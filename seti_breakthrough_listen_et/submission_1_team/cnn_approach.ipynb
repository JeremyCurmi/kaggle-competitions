{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Imports"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 18:27:51.490481: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-31 18:27:51.490512: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "import tensorflow as tf\n",
    "from random import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "data_path = '~/../../media/sf_data/'\n",
    "file_name = 'seti_breakthrough_listen_et'\n",
    "data_path = data_path + file_name"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "TARGET = 'target'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def get_train_file_path(image_id):\n",
    "    return f\"{data_path}/train/{image_id[0]}/{image_id}.npy\"\n",
    "\n",
    "def get_test_file_path(image_id):\n",
    "    return f\"{data_path}/test/{image_id[0]}/{image_id}.npy\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "train = pd.read_csv(data_path + '/train_labels.csv')\n",
    "train['file_path'] = train['id'].apply(get_train_file_path)\n",
    "train['file_path'] = train['file_path'].str.split('~/../..').str[-1]\n",
    "\n",
    "test = pd.read_csv(data_path + '/sample_submission.csv')\n",
    "test['file_path'] = test['id'].apply(get_test_file_path)\n",
    "test['file_path'] = test['file_path'].str.split('~/../..').str[-1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "outputs": [],
   "source": [
    "train_df, validation_df = train_test_split(train, test_size=0.33)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "[5287,\n 26678,\n 17852,\n 11683,\n 39239,\n 21753,\n 40727,\n 29848,\n 5449,\n 40355,\n 49274,\n 42508,\n 10463,\n 30398,\n 7922,\n 16347,\n 18883,\n 4647,\n 29978,\n 23865,\n 27303,\n 11585,\n 5166,\n 23752,\n 13489,\n 38943,\n 37226,\n 38851,\n 18959,\n 25341,\n 5071,\n 32694,\n 31370,\n 13020,\n 43858,\n 14183,\n 5434,\n 31605,\n 32134,\n 9777,\n 32696,\n 47963,\n 22111,\n 14319,\n 13027,\n 39125,\n 5556,\n 18633,\n 2383,\n 29973,\n 30499,\n 32352,\n 5552,\n 24104,\n 11858,\n 35715,\n 12529,\n 2325,\n 28512,\n 33455,\n 47767,\n 33836,\n 5393,\n 43217,\n 2239,\n 7488,\n 27453,\n 43203,\n 12391,\n 23957,\n 20847,\n 384,\n 28858,\n 16641,\n 25539,\n 17765,\n 4245,\n 16738,\n 33059,\n 7355,\n 43347,\n 3135,\n 37831,\n 43239,\n 43861,\n 20340,\n 29968,\n 24176,\n 43127,\n 47369,\n 49458,\n 23664,\n 15458,\n 6363,\n 44218,\n 47255,\n 38536,\n 11872,\n 9836,\n 22191]"
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [],
   "source": [
    "train_examples = []\n",
    "train_labels = []\n",
    "validation_examples = []\n",
    "validation_labels = []\n",
    "\n",
    "\n",
    "\n",
    "for i in train_df.index[:100].to_list():\n",
    "    raw_train = np.load(train_df.loc[i,'file_path'])\n",
    "\n",
    "    for raw_channel in raw_train:\n",
    "        train_examples.append(raw_channel.reshape(1,273, 256))\n",
    "        train_labels.append(train_df.loc[i,'target'].reshape(1))\n",
    "\n",
    "for i in validation_df.index[:100].to_list():\n",
    "    raw_valid = np.load(validation_df.loc[i,'file_path'])\n",
    "    for raw_channel in raw_valid:\n",
    "        validation_examples.append(raw_channel.reshape(1,273, 256))\n",
    "        validation_labels.append(validation_df.loc[i,'target'].reshape(1))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [],
   "source": [
    "train_examples = np.concatenate(train_examples, axis=0 )\n",
    "train_labels = np.concatenate(train_labels, axis=0)\n",
    "\n",
    "validation_examples = np.concatenate(validation_examples, axis=0 )\n",
    "validation_labels = np.concatenate(validation_labels, axis=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "data": {
      "text/plain": "(600, 273, 256)"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "(600,)"
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-31 18:52:46.077746: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 83865600 exceeds 10% of free system memory.\n",
      "2021-07-31 18:52:46.188257: W tensorflow/core/framework/cpu_allocator_impl.cc:80] Allocation of 83865600 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_examples, train_labels))\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((validation_examples, validation_labels))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "SHUFFLE_BUFFER_SIZE = 100\n",
    "\n",
    "train_dataset = train_dataset.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "validation_dataset = validation_dataset.batch(BATCH_SIZE)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "add() missing 1 required positional argument: 'layer'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m/tmp/ipykernel_20164/3276966955.py\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mSequential\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 5\u001B[0;31m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      6\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0madd\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/src/kaggle-competitions/env/lib/python3.7/site-packages/tensorflow/python/training/tracking/base.py\u001B[0m in \u001B[0;36m_method_wrapper\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    520\u001B[0m     \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mFalse\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    521\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 522\u001B[0;31m       \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmethod\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    523\u001B[0m     \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    524\u001B[0m       \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_self_setattr_tracking\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mprevious_value\u001B[0m  \u001B[0;31m# pylint: disable=protected-access\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: add() missing 1 required positional argument: 'layer'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add()\n",
    "model.add()\n",
    "model.add()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}